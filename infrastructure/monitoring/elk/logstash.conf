# Logstash Configuration v1.0.0
# Dependencies:
# - logstash-input-beats v7.17.0
# - logstash-filter-json v3.2.0
# - logstash-filter-grok v4.4.0
# - logstash-output-elasticsearch v11.0.0
# - logstash-filter-mutate v3.5.0
# - logstash-filter-date v3.1.0

# Global settings
pipeline.workers: ${PIPELINE_WORKERS:2}
pipeline.batch.size: ${BATCH_SIZE:125}
queue.type: ${QUEUE_TYPE:persisted}
queue.max_bytes: ${QUEUE_MAX_BYTES:1gb}

input {
  beats {
    port => 5044
    ssl => true
    ssl_certificate => "/etc/logstash/certs/logstash.crt"
    ssl_key => "/etc/logstash/certs/logstash.key"
    ssl_verify_mode => "force_peer"
    client_inactivity_timeout => 60
    include_codec_tag => true
    max_pending_requests => 2000
    tags => ["beats_input"]
  }

  tcp {
    port => 5000
    codec => json_lines
    ssl_enable => true
    ssl_verify => true
    ssl_cert => "/etc/logstash/certs/logstash.crt"
    ssl_key => "/etc/logstash/certs/logstash.key"
    tags => ["tcp_input"]
  }
}

filter {
  # JSON parsing
  json {
    source => "message"
    target => "parsed_json"
    remove_field => ["message"]
    skip_on_invalid_json => true
    tag_on_failure => ["_jsonparsefailure"]
  }

  # Application log parsing
  if "application" in [tags] {
    grok {
      match => {
        "message" => "%{TIMESTAMP_ISO8601:timestamp} %{LOGLEVEL:log_level} %{GREEDYDATA:log_message}"
      }
      tag_on_failure => ["_grokparsefailure", "application_parse_failure"]
    }
  }

  # Security event parsing
  if "security" in [tags] {
    grok {
      match => {
        "security_events" => "%{TIMESTAMP_ISO8601:timestamp} %{WORD:security_level} %{GREEDYDATA:security_message}"
      }
      pattern_definitions => {
        "SECURITY_EVENT" => "(?<event_type>ALERT|WARNING|INFO) (?<event_id>[A-Z0-9]+)"
      }
      tag_on_failure => ["_grokparsefailure", "security_parse_failure"]
    }
  }

  # Timestamp standardization
  date {
    match => ["timestamp", "ISO8601"]
    target => "@timestamp"
    tag_on_failure => ["_dateparsefailure"]
  }

  # Field enrichment
  mutate {
    add_field => {
      "environment" => "${ENV:production}"
      "app" => "task-management"
      "version" => "${APP_VERSION}"
      "datacenter" => "${DC_LOCATION}"
    }
    convert => {
      "response_time" => "integer"
      "status_code" => "integer"
    }
  }

  # Infrastructure log processing
  if "infrastructure" in [tags] {
    grok {
      match => {
        "message" => "%{SYSLOGBASE} %{GREEDYDATA:infra_message}"
      }
      tag_on_failure => ["_grokparsefailure", "infrastructure_parse_failure"]
    }
  }
}

output {
  elasticsearch {
    hosts => ["${ELASTICSEARCH_HOST:elasticsearch}:9200"]
    user => "${ELASTICSEARCH_USER}"
    password => "${ELASTICSEARCH_PASSWORD}"
    index => "task-management-logs-%{+YYYY.MM.dd}"
    template_name => "task-management"
    template_overwrite => true
    
    # SSL/TLS settings
    ssl => true
    ssl_certificate_verification => true
    
    # High availability settings
    sniffing => true
    pool_size => 4
    retry_initial_interval => "2s"
    retry_max_interval => "64s"
    retry_on_conflict => 5
    
    # Performance tuning
    bulk_max_size => 2048
    timeout => "60s"
    
    # Error handling
    failure_type_logging_whitelist => ["es_rejected_execution_exception"]
  }

  # Dead Letter Queue configuration
  dead_letter_queue {
    enable => true
    max_bytes => "1gb"
    path => "/var/log/logstash/dead_letter_queue"
  }

  # Conditional output for security events
  if "security" in [tags] {
    elasticsearch {
      hosts => ["${ELASTICSEARCH_HOST:elasticsearch}:9200"]
      user => "${ELASTICSEARCH_USER}"
      password => "${ELASTICSEARCH_PASSWORD}"
      index => "security-events-%{+YYYY.MM.dd}"
      template_name => "security-events"
      template_overwrite => true
      ssl => true
      ssl_certificate_verification => true
    }
  }
}